/**
 * ü§ñ SYST√àME MULTI-IA
 * 
 * Ce fichier permet de basculer facilement entre diff√©rents fournisseurs d'IA :
 * - Google Gemini (gratuit, recommand√©)
 * - OpenAI GPT-4 (payant, qualit√© maximale)
 * - Anthropic Claude (payant, bon √©quilibre)
 */

import { GoogleGenerativeAI } from '@google/generative-ai';
import OpenAI from 'openai';
import Anthropic from '@anthropic-ai/sdk';
import Groq from 'groq-sdk';

// Types
export type AIProvider = 'gemini' | 'openai' | 'claude' | 'groq';
export type AIAction = 'improve' | 'expand' | 'shorten' | 'simplify' | 'correct' | 'reformulate';

interface AIConfig {
  provider: AIProvider;
  apiKey: string;
  model?: string;
}

// Configuration par d√©faut (peut √™tre surcharg√©e via .env.local)
export const DEFAULT_AI_PROVIDER: AIProvider = (process.env.AI_PROVIDER as AIProvider) || 'gemini';

/**
 * Obtenir la configuration de l'IA active
 */
export function getAIConfig(): AIConfig {
  const provider = DEFAULT_AI_PROVIDER;

  switch (provider) {
    case 'gemini':
      return {
        provider: 'gemini',
        apiKey: process.env.GOOGLE_API_KEY || '',
        model: process.env.GEMINI_MODEL || 'gemini-1.5-flash' // Mod√®le par d√©faut chang√© pour plus de stabilit√©
      };
    
    case 'openai':
      return {
        provider: 'openai',
        apiKey: process.env.OPENAI_API_KEY || '',
        model: process.env.OPENAI_MODEL || 'gpt-4'
      };
    
    case 'claude':
      return {
        provider: 'claude',
        apiKey: process.env.ANTHROPIC_API_KEY || '',
        model: process.env.CLAUDE_MODEL || 'claude-3-sonnet-20240229'
      };
    
    case 'groq':
      return {
        provider: 'groq',
        apiKey: process.env.GROQ_API_KEY || '',
        model: process.env.GROQ_MODEL || 'llama-3.3-70b-versatile'
      };
    
    default:
      return {
        provider: 'groq',
        apiKey: process.env.GROQ_API_KEY || '',
        model: process.env.GROQ_MODEL || 'llama-3.3-70b-versatile'
      };
  }
}

/**
 * Obtenir les instructions de style selon le style s√©lectionn√©
 */
function getStyleInstructions(style: string): string {
  const styleMap: Record<string, string> = {
    general: "Utilise un style √©quilibr√©, clair et accessible.",
    academic: "Adopte un ton formel et acad√©mique. Utilise un vocabulaire scientifique et des formulations rigoureuses.",
    creative: "Sois cr√©atif et litt√©raire. Utilise des m√©taphores, des images po√©tiques et un style √©l√©gant.",
    professional: "Utilise un ton professionnel d'entreprise. Style formel mais accessible.",
    casual: "Adopte un ton d√©contract√© et amical. Parle comme si tu conversais avec un ami.",
    storytelling: "Raconte comme un conteur d'histoires. Cr√©e du suspense et de l'√©motion.",
    poetic: "Utilise un style po√©tique et lyrique. Privil√©gie la beaut√© de la langue.",
    journalistic: "Adopte un style journalistique factuel et objectif. Va droit au but.",
    technical: "Sois pr√©cis et technique. Utilise le vocabulaire sp√©cialis√© appropri√©.",
    persuasive: "Sois convaincant et argumentatif. Structure ton propos pour persuader.",
    educational: "Explique de mani√®re p√©dagogique et didactique. Rends le sujet facile √† comprendre.",
    training_guide: "√âcris comme un guide de formation pratique. Structure en √©tapes claires et num√©rot√©es. Inclus des objectifs, des exercices pratiques, des exemples concrets et des points de v√©rification. Utilise un ton instructif mais encourageant. Format: Introduction ‚Üí Objectifs ‚Üí √âtapes d√©taill√©es ‚Üí Pratique ‚Üí R√©sum√©.",
    historical: "Adopte un style historique document√©. Contextualise les faits chronologiquement.",
    fantasy: "√âcris dans un style merveilleux et √©pique. Cr√©e un univers fantastique.",
    scifi: "Utilise un style science-fiction futuriste. Int√®gre des √©l√©ments technologiques.",
    romantic: "Adopte un ton romantique et √©motionnel. Exprime les sentiments avec sensibilit√©.",
    humor: "Sois l√©ger et amusant. Utilise l'humour avec subtilit√©.",
    mystery: "Cr√©e du suspense et de l'intrigue. Maintiens le myst√®re.",
    philosophical: "Adopte un ton philosophique r√©flexif. Pose des questions profondes."
  };
  return styleMap[style] || styleMap.general;
}

/**
 * Construire le prompt selon l'action demand√©e, le style et le nombre de pages
 */
export function buildPrompt(action: AIAction, text: string, style: string = 'general', desiredPages?: number): string {
  const styleInstructions = getStyleInstructions(style);
  const pageInstructions = desiredPages 
    ? `\n12. IMP√âRATIF ABSOLU NON N√âGOCIABLE: L'utilisateur veut EXACTEMENT ${desiredPages} pages. Tu DOIS g√©n√©rer AU MINIMUM ${desiredPages * 300} mots (300 mots/page). OBJECTIF: ${desiredPages * 300} MOTS MINIMUM. Si tu g√©n√®res moins, c'est un √âCHEC TOTAL. D√âVELOPPE AU MAXIMUM: ajoute des chapitres d√©taill√©s, des sous-sections, des exemples concrets, du contexte historique/culturel complet, des anecdotes, des descriptions, des analyses approfondies. MULTIPLIE par 3-5 le contenu jusqu'√† atteindre ${desiredPages * 300} mots ABSOLUMENT. NE SOIS JAMAIS CONCIS, D√âVELOPPE TOUT AU MAXIMUM.`
    : '';
  const langHint = `
R√àGLES STRICTES - TU DOIS ABSOLUMENT LES SUIVRE:
1. Conserve EXACTEMENT la langue d'origine du texte
2. ${styleInstructions}
3. G√âN√àRE LE CONTENU R√âEL ET COMPLET - PAS de m√©ta-description comme "Je vais √©crire..." ou "Voici ce que je vais faire..."
4. Retourne UNIQUEMENT le texte transform√©, SANS pr√©ambule, SANS explication, SANS balises, SANS commentaires
5. Ne commence PAS par "Voici le texte..." ou "Le texte am√©lior√© est..." ou "Je vais r√©diger..."
6. NE DIS PAS ce que tu vas faire, FAIS-LE directement
7. INTERDICTION de d√©crire le processus ou le plan - G√âN√àRE le contenu final imm√©diatement
8. Retourne DIRECTEMENT le texte transform√©, rien d'autre
9. INTERDICTION de mettre des balises HTML ou Markdown autour du texte
10. COMMENCE directement par le contenu transform√©
11. G√âN√àRE un contenu UNIQUE et ORIGINAL - Seed: ${Date.now() + Math.random()}${pageInstructions}
`;

  const prompts: Record<AIAction, string> = {
    improve: `Tu es un √©crivain professionnel. Am√©liore ce texte en gardant LE M√äME SENS et LA M√äME INTENTION que l'utilisateur.

R√àGLES STRICTES:
1. RESPECTE l'intention de l'utilisateur : si c'est une simple demande, reste simple
2. Am√©liore MOD√âR√âMENT le style et la fluidit√© (pas de transformation radicale)
3. Corrige les erreurs grammaticales
4. N'ajoute PAS de vocabulaire ultra-acad√©mique sauf si le contexte l'exige
5. Garde le TON NATUREL du texte original
6. D√©veloppe l√©g√®rement SEULEMENT si c'est n√©cessaire pour la clart√©
${langHint}

TEXTE √Ä AM√âLIORER:
${text}

TEXTE AM√âLIOR√â (commence directement, sans introduction):`,

    expand: `Tu es un √©crivain expert. D√©veloppe ce texte de mani√®re TR√àS SUBSTANTIELLE en ajoutant √©norm√©ment de d√©tails, d'exemples concrets, d'explications approfondies, de descriptions riches, d'anecdotes, de contexte historique/scientifique/culturel selon le sujet. 

IMPORTANT: MULTIPLIE la longueur par 3 √† 5 minimum. Si le texte fait 200 mots, g√©n√®re 600-1000 mots. D√©veloppe CHAQUE id√©e en profondeur. N'h√©site pas √† √™tre long et d√©taill√©.
${langHint}

TEXTE √Ä D√âVELOPPER:
${text}

TEXTE D√âVELOPP√â ET TR√àS ENRICHI (commence directement):`,

    shorten: `Tu es un r√©dacteur expert. Condense ce texte en gardant uniquement les id√©es principales et essentielles. R√©duis d'environ 30% tout en pr√©servant le sens et la clart√©.
${langHint}

TEXTE √Ä CONDENSER:
${text}

TEXTE CONDENS√â (commence directement):`,

    simplify: `Tu es un expert en vulgarisation. Simplifie ce texte pour le rendre tr√®s accessible et facile √† comprendre. Utilise un vocabulaire simple, des phrases courtes et claires.
${langHint}

TEXTE √Ä SIMPLIFIER:
${text}

TEXTE SIMPLIFI√â (commence directement):`,

    correct: `Tu es un correcteur professionnel. Corrige toutes les erreurs de grammaire, d'orthographe, de ponctuation et de syntaxe dans ce texte. Ne change que ce qui est incorrect. Garde le style et le sens original.
${langHint}

TEXTE √Ä CORRIGER:
${text}

TEXTE CORRIG√â (commence directement):`,

    reformulate: `Tu es un r√©dacteur cr√©atif. R√©√©cris compl√®tement ce texte avec un style totalement diff√©rent tout en gardant exactement le m√™me message et les m√™mes informations. Sois tr√®s cr√©atif dans la reformulation.
${langHint}

TEXTE √Ä REFORMULER:
${text}

TEXTE REFORMUL√â (commence directement):`
  };

  return prompts[action];
}

/**
 * Liste des mod√®les Gemini disponibles (par ordre de pr√©f√©rence)
 */
const GEMINI_MODELS = [
  'gemini-1.5-flash',      // Mod√®le stable et rapide
  'gemini-1.5-pro',        // Mod√®le plus puissant
  'gemini-pro',            // Mod√®le classique
];

/**
 * Fonction helper pour attendre (sleep)
 */
function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * Appeler Google Gemini avec retry automatique et fallback de mod√®les
 */
async function callGemini(prompt: string, apiKey: string): Promise<string> {
  const genAI = new GoogleGenerativeAI(apiKey);
  
  // Tenter avec plusieurs mod√®les en cas d'√©chec
  for (let modelIndex = 0; modelIndex < GEMINI_MODELS.length; modelIndex++) {
    const modelName = GEMINI_MODELS[modelIndex];
    const model = genAI.getGenerativeModel({ model: modelName });
    
    // Retry avec backoff exponentiel (3 tentatives par mod√®le)
    for (let attempt = 1; attempt <= 3; attempt++) {
      try {
        console.log(`ü§ñ Tentative ${attempt}/3 avec mod√®le: ${modelName}`);
        
        const result = await model.generateContent({
          contents: [{ role: 'user', parts: [{ text: prompt }] }],
          generationConfig: {
            temperature: 0.8,
            topK: 40,
            topP: 0.95,
            maxOutputTokens: 16384,
          },
        });

        const response = await result.response;
        const text = response.text();
        
        if (!text || text.trim().length === 0) {
          throw new Error('L\'API Gemini a retourn√© une r√©ponse vide');
        }
        
        console.log(`‚úÖ Succ√®s avec ${modelName} (tentative ${attempt})`);
        return text;
        
      } catch (error: any) {
        const isLastAttempt = attempt === 3;
        const isLastModel = modelIndex === GEMINI_MODELS.length - 1;
        const errorMsg = error.message || 'Erreur inconnue';
        
        console.error(`‚ùå Erreur ${modelName} (tentative ${attempt}/3):`, errorMsg);
        
        // Erreur 503 (Service Unavailable / Overloaded)
        if (errorMsg.includes('503') || errorMsg.includes('overloaded')) {
          if (isLastAttempt && isLastModel) {
            throw new Error('Le service Google Gemini est temporairement surcharg√©. Veuillez r√©essayer dans 1-2 minutes ou basculer sur OpenAI/Claude dans les param√®tres.');
          }
          
          if (!isLastAttempt) {
            // Attendre avant de r√©essayer (backoff exponentiel: 2s, 4s, 8s)
            const waitTime = Math.pow(2, attempt) * 1000;
            console.log(`‚è≥ Mod√®le surcharg√©, nouvelle tentative dans ${waitTime/1000}s...`);
            await sleep(waitTime);
            continue; // R√©essayer avec le m√™me mod√®le
          } else {
            // Passer au mod√®le suivant
            console.log(`üîÑ Passage au mod√®le suivant: ${GEMINI_MODELS[modelIndex + 1]}`);
            break; // Sortir de la boucle de retry pour essayer le mod√®le suivant
          }
        }
        
        // Autres erreurs
        if (errorMsg.includes('timeout')) {
          throw new Error('Timeout: La g√©n√©ration a pris trop de temps. Essayez avec un texte plus court ou r√©essayez.');
        }
        if (errorMsg.includes('429')) {
          throw new Error('Quota API d√©pass√©. Attendez quelques minutes ou cr√©ez une nouvelle cl√© API.');
        }
        if (errorMsg.includes('403') || errorMsg.includes('401')) {
          throw new Error('Cl√© API invalide ou expir√©e. V√©rifiez votre cl√© dans .env.local');
        }
        
        // Si derni√®re tentative du dernier mod√®le, propager l'erreur
        if (isLastAttempt && isLastModel) {
          throw new Error(`Erreur Gemini: ${errorMsg}`);
        }
        
        // Attendre avant de r√©essayer
        if (!isLastAttempt) {
          const waitTime = Math.pow(2, attempt) * 1000;
          await sleep(waitTime);
        }
      }
    }
  }
  
  throw new Error('Tous les mod√®les Gemini ont √©chou√©. Veuillez r√©essayer plus tard.');
}

/**
 * Appeler OpenAI GPT-4
 */
async function callOpenAI(prompt: string, apiKey: string, model: string): Promise<string> {
  const openai = new OpenAI({
    apiKey: apiKey
  });

  const completion = await openai.chat.completions.create({
    model: model,
    messages: [
      {
        role: 'system',
        content: 'Tu es un √©crivain professionnel expert en transformation de texte.'
      },
      {
        role: 'user',
        content: prompt
      }
    ],
    temperature: 0.8,
    max_tokens: 8192
  });

  return completion.choices[0].message.content || '';
}

/**
 * Appeler Anthropic Claude
 */
async function callClaude(prompt: string, apiKey: string, model: string): Promise<string> {
  const anthropic = new Anthropic({
    apiKey: apiKey
  });

  const message = await anthropic.messages.create({
    model: model,
    max_tokens: 8192,
    messages: [
      {
        role: 'user',
        content: prompt
      }
    ],
    temperature: 0.8
  });

  const content = message.content[0];
  return content.type === 'text' ? content.text : '';
}

/**
 * Appeler Groq (Llama 3.1)
 */
async function callGroq(prompt: string, apiKey: string, model: string): Promise<string> {
  const groq = new Groq({
    apiKey: apiKey
  });

  try {
    const completion = await groq.chat.completions.create({
      model: model,
      messages: [
        {
          role: 'system',
          content: 'Tu es un √©crivain professionnel expert en transformation de texte.'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.8,
      max_tokens: 8192,
      top_p: 0.95,
    });

    return completion.choices[0]?.message?.content || '';
  } catch (error: any) {
    console.error('‚ùå Groq API Error:', error);
    if (error.message?.includes('429')) {
      throw new Error('Quota Groq d√©pass√© (30 req/min). Attendez quelques secondes.');
    }
    if (error.message?.includes('401') || error.message?.includes('403')) {
      throw new Error('Cl√© API Groq invalide. V√©rifiez votre cl√© dans .env.local');
    }
    throw new Error(`Erreur Groq: ${error.message || 'Erreur inconnue'}`);
  }
}

/**
 * Nettoyer la r√©ponse de l'IA
 */
function cleanAIResponse(text: string): string {
  return text
    .replace(/^(Voici le texte.*?:|Le texte.*?est.*?:|Texte.*?:)\s*/i, '')
    .replace(/^```.*?\n/g, '')
    .replace(/\n```$/g, '')
    .trim();
}

/**
 * FONCTION PRINCIPALE : G√©n√©rer du contenu avec l'IA configur√©e
 */
export async function generateWithAI(action: AIAction, text: string, style: string = 'general', desiredPages?: number): Promise<string> {
  const config = getAIConfig();

  console.log('ü§ñ Using AI provider:', config.provider, '- Model:', config.model, '- Style:', style, '- Desired pages:', desiredPages || 'not specified');

  if (!config.apiKey) {
    throw new Error(`Cl√© API manquante pour ${config.provider}. Configurez-la dans .env.local`);
  }

  // Construire le prompt avec le style et le nombre de pages
  const prompt = buildPrompt(action, text, style, desiredPages);

  let processedText: string;

  // Appeler le bon fournisseur
  switch (config.provider) {
    case 'gemini':
      processedText = await callGemini(prompt, config.apiKey);
      break;

    case 'openai':
      processedText = await callOpenAI(prompt, config.apiKey, config.model!);
      break;

    case 'claude':
      processedText = await callClaude(prompt, config.apiKey, config.model!);
      break;

    case 'groq':
      processedText = await callGroq(prompt, config.apiKey, config.model!);
      break;

    default:
      throw new Error(`Fournisseur IA non support√©: ${config.provider}`);
  }

  // Nettoyer la r√©ponse
  return cleanAIResponse(processedText);
}

/**
 * Obtenir le nom complet du fournisseur actif
 */
export function getProviderName(): string {
  const provider = DEFAULT_AI_PROVIDER;
  const names = {
    gemini: 'Google Gemini',
    openai: 'OpenAI GPT-4',
    claude: 'Anthropic Claude',
    groq: 'Groq (Llama 3.1)'
  };
  return names[provider] || provider;
}

/**
 * V√©rifier si l'IA est correctement configur√©e
 */
export function isAIConfigured(): boolean {
  const config = getAIConfig();
  return !!config.apiKey && config.apiKey.length > 10;
}
